{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Mini Lab\n",
    "\n",
    "The aim of this lab is to gain a better understanding of the impact regularization has on the performance of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from IPython.display import Math, display\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    SGDRegressor,\n",
    "    Ridge,\n",
    "    Lasso\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the \"data\"\n",
    "\n",
    "The values of our input are randomly sampled from a normal distribution, which is often used to describe bell-shaped processes which tends towards central values with tails that quickly fall off.\n",
    "\n",
    "The values we are trying to predict will be a cosine transformation of the inputs, with a slight slope so as to break the symmetry, and some additional normally distributed noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gen_func(x, noise=0.):\n",
    "    return 0.15*x + np.cos(x*np.pi/2.) + scipy.stats.norm.rvs(size=len(x), random_state=2)*noise\n",
    "\n",
    "n = 1000\n",
    "f_train = 0.9\n",
    "x = scipy.stats.norm.rvs(loc=0, scale=0.8, size=n, random_state=3)\n",
    "y = gen_func(x, noise=0.2)\n",
    "\n",
    "n_train = int(f_train*n)\n",
    "x_train = x[:n_train]\n",
    "y_train = y[:n_train]\n",
    "x_test = x[n_train:]\n",
    "y_test = y[n_train:]\n",
    "x_grid = np.linspace(-4, 4, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the function\n",
    "\n",
    "We will try to learn the relationship between the inputs and the values using polynomial regression without regression, using lasso, and using ridge.\n",
    "\n",
    "Since the cosine is a complicated function to learn, we will have to use a high-order polynomial to describe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the order of the polynomial fit\n",
    "n_poly = 22\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8,8), gridspec_kw={'height_ratios':[3, 1]})\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(x_train, y_train, 'o', alpha=0.1, label='data')\n",
    "ax.plot(x_grid, gen_func(x_grid, noise=0), 'k--', label='Ground Truth')\n",
    "\n",
    "# Fit the data using three regression methods\n",
    "for clf, label in (\n",
    "    (LinearRegression(), 'Linear Regression'),\n",
    "    (Ridge(alpha=0.01), 'Ridge'),\n",
    "    (Lasso(alpha=0.0005), 'Lasso'),\n",
    "    \n",
    "):\n",
    "\n",
    "    print '-='*20\n",
    "    print clf\n",
    "\n",
    "    # The raw transformation of inputs can result in a large range of values.\n",
    "    # Use a scaler to make sure each of the inputs to the regression are comparable.\n",
    "    ss = StandardScaler()\n",
    "    poly_train = ss.fit_transform(np.array([np.power(x_train, i) for i in range(1, n_poly)]).T)\n",
    "    poly_test = ss.transform(np.array([np.power(x_test, i) for i in range(1, n_poly)]).T)\n",
    "    poly_grid = ss.transform(np.array([np.power(x_grid, i) for i in range(1, n_poly)]).T)\n",
    "\n",
    "    # Fit and evaluate the regression\n",
    "    clf.fit(poly_train, y_train)\n",
    "    fit_r2 = clf.score(poly_train, y_train)\n",
    "    y_pred = clf.predict(poly_test)\n",
    "    mse_pred = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    print 'Fit R^2 = %.2f, prediction MSE = %.5f' % (fit_r2, mse_pred)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    y_pred = clf.predict(poly_grid)\n",
    "    ax.plot(x_grid, y_pred, '-', label=label)\n",
    "    \n",
    "    vals = 'y = %s' % (\n",
    "        ' + '.join(\n",
    "            [('%.2f~x^{%d}' % (coef, power))\n",
    "             for power, coef\n",
    "             in enumerate(clf.coef_)\n",
    "            ])\n",
    "    )\n",
    "    display(Math(vals))\n",
    "\n",
    "    ax = axs[1]\n",
    "    ax.plot(np.abs(clf.coef_), 'o', alpha=0.5, label=label)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.legend(loc='upper center', ncol=3)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_ylim(0, 1.3)\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_ylabel('Absolute Value')\n",
    "ax.legend(loc='best', ncol=3)\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Questions\n",
    "* How did the different types of regularization affect the coefficients?\n",
    "  * How are they changed if we increase or decrease the alpha parameter?\n",
    "  * Does the number of non-zero coefficients have an impact on the quality of the predictions?\n",
    "  * Does the magnitude of the coefficients have an impact on the quality of the predictions?\n",
    "  * What about the behavior in the low-frequency tails?\n",
    "* Why are the mean squared error values so much smaller than for the previous exercise?\n",
    "* What would happen if the training and/or testing dataset was more evenly spaced out between -3 and 3?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
